{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitb91cf2c2c7a74f58a626e59dae991c5f",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "df = pd.read_csv('data.csv', header = 0)\n",
    "df = df.drop(['id'], axis=1)\n",
    "diagnosis = df['diagnosis']\n",
    "df['catNB'] = pd.factorize(df['diagnosis'].values)[0]\n",
    "dfLabels = df['catNB'] \n",
    "labels = ['M', \"B\"]\n",
    "\n",
    "features = ['radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean'] # Features I will use \n",
    "\n",
    "bestAccuracy = 0.0\n",
    "bestParams = None\n",
    "bestCombination = []\n",
    "bestDF = None\n",
    "bestModel = None\n",
    "\n",
    "k = 10 # Number of splits\n",
    "maxRange = 20\n",
    "\n",
    "def rSubset(arr, r): \n",
    "    # return list of all subsets of length r \n",
    "    # to deal with duplicate subsets use  \n",
    "    # set(list(combinations(arr, r))) \n",
    "    return list(combinations(arr, r)) "
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "for nNumberOfFeatures in range(2, len(features)+1):\n",
    "    possibleCombinations = rSubset(features, nNumberOfFeatures) # Creates complete list of all combinations of\n",
    "    for combination in possibleCombinations:\n",
    "        currentDF = pd.DataFrame()\n",
    "        i = 0\n",
    "        for feature in combination:\n",
    "            currentDF.insert(i, feature, df[feature].to_list(), True)\n",
    "            i += 1\n",
    "\n",
    "        x = currentDF\n",
    "        y = dfLabels\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=5)\n",
    "        # Set up the grid of parameters\n",
    "        hyperParams = {'weights': ['uniform', 'distance'],\n",
    "                    'n_neighbors': range(2, maxRange),\n",
    "                    'p' : range(1, maxRange)}\n",
    "        # Train the model in the grid search\n",
    "        kFolds = StratifiedKFold(n_splits = k, shuffle = True, random_state = 0)\n",
    "        search = GridSearchCV(model, hyperParams, cv = kFolds, scoring = 'accuracy')\n",
    "        search = search.fit(x, y)\n",
    "        # Show some of the results using a dataframe\n",
    "        dfResults = pd.DataFrame(search.cv_results_)\n",
    "        results = dfResults[['param_weights', 'param_n_neighbors', 'param_p', \\\n",
    "                    'mean_test_score', 'std_test_score']]\n",
    "        model = search.best_estimator_\n",
    "        # print(search.best_params_)\n",
    "\n",
    "        maxDepthRange = range(1, maxRange)\n",
    "        trainScores, testScores = validation_curve(model, x, y, \\\n",
    "                    param_name = 'n_neighbors', param_range = maxDepthRange, \\\n",
    "                    cv = kFolds, scoring = 'accuracy')\n",
    "        trainScoresMean = np.mean(trainScores, axis=1)\n",
    "        trainScoresStd = np.std(trainScores, axis=1)\n",
    "        testScoresMean = np.mean(testScores, axis=1)\n",
    "        testScoresStd = np.std(testScores, axis=1)\n",
    "\n",
    "        filteredTestScoresMean = [] # Include all test scores that are within STD of train scores mean\n",
    "        filteredTestScoresMeanIndex = [] \n",
    "        for i in range(0, len(trainScoresMean)):\n",
    "            if testScoresMean[i] + testScoresStd[i] >= trainScoresMean[i]:\n",
    "                filteredTestScoresMean.append(testScoresMean[i])\n",
    "                filteredTestScoresMeanIndex.append(i)\n",
    "\n",
    "        print(\"Test Scores Left:\", len(filteredTestScoresMean))\n",
    "\n",
    "        bestScore = 0.0\n",
    "        bestScoreIndex = 0\n",
    "        for i in range(0, len(filteredTestScoresMean)):\n",
    "            if filteredTestScoresMean[i] > bestScore:\n",
    "                bestScore = filteredTestScoresMean[i]\n",
    "                bestScoreIndex = filteredTestScoresMeanIndex[i]\n",
    "\n",
    "        if len(filteredTestScoresMean) == 0:\n",
    "            bestScore = testScoresMean[search.best_params_['n_neighbors'] -1 ]\n",
    "            bestScoreIndex = search.best_params_['n_neighbors'] - 1\n",
    "        \n",
    "        highestAccuracy = (bestScore, bestScoreIndex) # Percent, depth \n",
    "        # Add standard deviation checking\n",
    "\n",
    "        search.best_params_['n_neighbors'] = bestScoreIndex + 1\n",
    "\n",
    "        print(\"Accuracy with\", combination, \":\", highestAccuracy[0])\n",
    "        print(\"Params:\", search.best_params_, '\\n')\n",
    "\n",
    "        if highestAccuracy[0] > bestAccuracy:\n",
    "            bestAccuracy = highestAccuracy[0]\n",
    "            bestCombination = combination\n",
    "            bestDF = currentDF\n",
    "            bestParams = search.best_params_\n",
    "            bestModel = model\n",
    "\n",
    "            confusion = np.zeros((2,2))\n",
    "            scores = cross_val_score(model, x, y, cv = k)\n",
    "            predicted = cross_val_predict(model, x, y, cv = k)\n",
    "            accuracy = scores.mean()\n",
    "            confusion = confusion_matrix(y, predicted)\n",
    "            confDF = pd.DataFrame(confusion)\n",
    "            confDF.columns = labels\n",
    "            confDF.index = labels\n",
    "\n",
    "            fig, ax = plt.subplots() # figsize=(6,10)\n",
    "            plt.title('Confusion matrix with best accuracy (Stratified K-Fold [K=10])\\nwith Decision Tree')\n",
    "            ax = sns.heatmap(confDF, annot = True, square=True, linewidth=3)\n",
    "            fig.savefig('Best Heatmap Stratified K-Fold with KNN.png')\n",
    "            plt.close()"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "print(\"Best Accuracy:\", bestAccuracy)\n",
    "print(\"Feature Combination of Best Accuracy:\", bestCombination)\n",
    "print(\"Best Parameters of Best Accuracy:\", bestParams)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "x = bestDF\n",
    "y = dfLabels\n",
    "model = bestModel\n",
    "\n",
    "maxDepthRange = range(1, maxRange)\n",
    "trainScores, testScores = validation_curve(model, x, y, \\\n",
    "            param_name = 'n_neighbors', param_range = maxDepthRange, \\\n",
    "            cv = kFolds, scoring = 'accuracy')\n",
    "trainScoresMean = np.mean(trainScores, axis=1)\n",
    "trainScoresStd = np.std(trainScores, axis=1)\n",
    "testScoresMean = np.mean(testScores, axis=1)\n",
    "testScoresStd = np.std(testScores, axis=1)\n",
    "\n",
    "plt.plot(maxDepthRange, trainScoresMean, label = 'Training Score', \\\n",
    "         color = 'darkorange', lw = 1, marker = 'o', markersize = 3)\n",
    "plt.fill_between(maxDepthRange, trainScoresMean - trainScoresStd, \\\n",
    "                 trainScoresMean + trainScoresStd, alpha = 0.2, \\\n",
    "                 color = 'darkorange', lw = 1)\n",
    "plt.plot(maxDepthRange, testScoresMean, label = 'Validation Score', \\\n",
    "         color = 'navy', lw = 1, marker = 's', markersize = 3)\n",
    "plt.fill_between(maxDepthRange, testScoresMean - testScoresStd, \\\n",
    "                 testScoresMean + testScoresStd, alpha = 0.2, \\\n",
    "                 color = 'navy', lw = 1)\n",
    "\n",
    "\n",
    "plt.title(\"Validation Curve with Best KNN Classifier\")\n",
    "plt.xlabel('n_neighbors Parameter')\n",
    "plt.ylabel(\"Score (%)\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv = k)\n",
    "predicted = cross_val_predict(model, x, y, cv = k)\n",
    "accuracy = scores.mean()\n",
    "confusion = confusion_matrix(y, predicted)\n",
    "confDF = pd.DataFrame(confusion)\n",
    "confDF.columns = labels\n",
    "confDF.index = labels\n",
    "\n",
    "fig, ax = plt.subplots() # figsize=(6,10)\n",
    "plt.title('Confusion Matrix with Best Accuracy (KNN)')\n",
    "ax = sns.heatmap(confDF, annot = True, square=True, linewidth=3)\n",
    "fig.savefig('Best Heatmap KNN.png')\n",
    "plt.close()\n",
    "\n"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "#PCA Analysis\n",
    "pca = PCA(n_components = 2)\n",
    "print(\"bestDF:\", bestDF)\n",
    "x = bestDF.values\n",
    "print(x)\n",
    "pca.fit(x)\n",
    "print('Components using Scikit-learn =')\n",
    "print(pca.singular_values_)\n",
    "print(pca.components_)\n",
    "xP = pca.transform(x)\n",
    "currentDFPCA = pd.DataFrame(data = xP, columns = ['eig1', 'eig2'])\n",
    "\n",
    "#print(dfLabels)\n",
    "X = currentDFPCA\n",
    "Y = dfLabels # Labels\n",
    "\n",
    "# Plotting decision regions\n",
    "X = X.to_numpy()\n",
    "#print(\"X:\", X)\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 #Compute boundaries of painting space\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max-x_min)/1000),\n",
    "                    np.arange(y_min, y_max, (y_max-y_min)/1000)) #tesselation 0.1 - resolution\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "print(np.c_[xx.ravel(), yy.ravel()].shape)\n",
    "Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()])) # Predicting after inversing the PCA\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Defining the colors to use\n",
    "colors=['blue', 'red']\n",
    "markers = ['s', 'p']\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "currentDFPCA['diagnosis'] = diagnosis\n",
    "\n",
    "# Plotting\n",
    "#print(currentDFPCA.head())\n",
    "ax = sns.scatterplot(data=currentDFPCA, x='eig1', y='eig2', hue = \"diagnosis\", palette=colors, style=\"diagnosis\", markers=markers)\n",
    "ax.contourf(xx, yy, Z, alpha=0.2, cmap=cmap) # Paint between boarders\n",
    "ax.set_title('Best KNN (based on Filtered Test Scores) Decision Regions plotted on PCA Space')\n",
    "plt.show()"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  }
 ]
}