{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analysisSoftVotingClassifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import *\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.tree import *\n",
        "from sklearn.model_selection import *\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from itertools import combinations\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "df = pd.read_csv('data.csv', header = 0)\n",
        "df = df.drop(['id'], axis=1)\n",
        "diagnosis = df['diagnosis']\n",
        "df['catNB'] = pd.factorize(df['diagnosis'].values)[0]\n",
        "dfLabels = df['catNB'] \n",
        "labels = ['M', \"B\"]\n",
        "\n",
        "features = ['radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean'] # Features I will use \n",
        "\n",
        "bestAccuracy = 0.0\n",
        "bestParams = None\n",
        "bestCombination = []\n",
        "bestDF = None\n",
        "bestModel = None\n",
        "\n",
        "k = 10 # Number of splits\n",
        "maxRange = [[92.3, 92.1, 92.6, 92.6, 93.3]]\n",
        "\n",
        "def rSubset(arr, r): \n",
        "    # return list of all subsets of length r \n",
        "    # to deal with duplicate subsets use  \n",
        "    # set(list(combinations(arr, r))) \n",
        "    return list(combinations(arr, r)) "
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "103eCm_w8oaC"
      },
      "source": [
        "Non-Poly Kernel Tests:"
      ]
    },
    {
      "source": [
        "for nNumberOfFeatures in range(2, len(features)+1):\n",
        "    possibleCombinations = rSubset(features, nNumberOfFeatures) # Creates complete list of all combinations of\n",
        "    for combination in possibleCombinations:\n",
        "        currentDF = pd.DataFrame()\n",
        "        i = 0\n",
        "        for feature in combination:\n",
        "            currentDF.insert(i, feature, df[feature].to_list(), True)\n",
        "            i += 1\n",
        "\n",
        "        x = currentDF\n",
        "        y = dfLabels\n",
        "\n",
        "        clf0 = GaussianNB()\n",
        "        clf1 = DecisionTreeClassifier(random_state = 0, criterion = 'gini', max_depth=2)\n",
        "        clf2 = KNeighborsClassifier(n_neighbors=7, weights= 'uniform', p=2)\n",
        "        clf3 = SVC(C=100, gamma='scale', kernel='rbf', probability=True)\n",
        "        clf4 = SVC(C=100, kernel='poly', degree=4, probability=True)\n",
        "\n",
        "        model = VotingClassifier(estimators=[ ('gnb', clf0), ('dt', clf1), ('knn', clf2),\n",
        "                                    ('svc', clf3), ('svc2', clf4)])\n",
        "\n",
        "    \n",
        "        # Set up the grid of parameters \n",
        "        hyperParams = { 'voting' : ['soft', 'hard'],\n",
        "                       'weights' : maxRange }\n",
        "        # Train the model in the grid search\n",
        "        kFolds = StratifiedKFold(n_splits = k, shuffle = True, random_state = 0)\n",
        "        search = GridSearchCV(model, hyperParams, cv = kFolds, scoring = 'accuracy')\n",
        "        search = search.fit(x, y)\n",
        "        # Show some of the results using a dataframe\n",
        "        dfResults = pd.DataFrame(search.cv_results_)\n",
        "        results = dfResults[['param_voting', 'param_weights', \\\n",
        "                    'mean_test_score', 'std_test_score']]\n",
        "        model = search.best_estimator_\n",
        "        # print(search.best_params_)\n",
        "\n",
        "        kFolds = StratifiedKFold(n_splits = k, shuffle = True, random_state = 0)\n",
        "        scores = cross_val_score(model, x, y, cv = kFolds)\n",
        "        predicted = cross_val_predict(model, x, y, cv = kFolds)\n",
        "        accuracy = scores.mean()\n",
        "        confusion = confusion_matrix(y, predicted)\n",
        "        confDF = pd.DataFrame(confusion)\n",
        "        confDF.columns = labels\n",
        "        confDF.index = labels\n",
        "\n",
        "        print(\"Accuracy with\", combination, \":\", accuracy)\n",
        "        print(\"Params:\", search.best_params_, '\\n')\n",
        "\n",
        "        if accuracy > bestAccuracy:\n",
        "            bestAccuracy = accuracy\n",
        "            bestCombination = combination\n",
        "            bestDF = currentDF\n",
        "            bestParams = search.best_params_\n",
        "            bestModel = model\n",
        "\n",
        "            confusion = np.zeros((2,2))\n",
        "            scores = cross_val_score(bestModel, x, y, cv = kFolds)\n",
        "            predicted = cross_val_predict(bestModel, x, y, cv = kFolds)\n",
        "            accuracy = scores.mean()\n",
        "            confusion = confusion_matrix(y, predicted)\n",
        "            confDF = pd.DataFrame(confusion)\n",
        "            confDF.columns = labels\n",
        "            confDF.index = labels\n",
        "\n",
        "            fig, ax = plt.subplots() # figsize=(6,10)\n",
        "            plt.title('Confusion matrix with best accuracy with Voting Classifier')\n",
        "            ax = sns.heatmap(confDF, annot = True, square=True, linewidth=3)\n",
        "            fig.savefig('Best Heatmap VC Weighted.png')\n",
        "            plt.close()"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy with ('radius_mean', 'perimeter_mean') : 0.8822994987468672\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'area_mean') : 0.892888471177945\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'compactness_mean') : 0.8981203007518797\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'concavity_mean') : 0.9139097744360901\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'concave points_mean') : 0.8980889724310778\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'area_mean') : 0.8893483709273182\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'compactness_mean') : 0.8911027568922305\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'concavity_mean') : 0.8963972431077695\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'concave points_mean') : 0.8945802005012531\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('area_mean', 'compactness_mean') : 0.8928571428571429\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('area_mean', 'concavity_mean') : 0.8928884711779448\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('area_mean', 'concave points_mean') : 0.8946115288220552\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('compactness_mean', 'concavity_mean') : 0.8698621553884711\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('compactness_mean', 'concave points_mean') : 0.9050125313283208\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('concavity_mean', 'concave points_mean') : 0.9190789473684211\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'area_mean') : 0.8928571428571429\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'compactness_mean') : 0.8911027568922305\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'concavity_mean') : 0.8981203007518797\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'concave points_mean') : 0.899874686716792\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'area_mean', 'compactness_mean') : 0.8928571428571429\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'area_mean', 'concavity_mean') : 0.8893796992481203\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'area_mean', 'concave points_mean') : 0.8946115288220552\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'compactness_mean', 'concavity_mean') : 0.9103696741854638\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'compactness_mean', 'concave points_mean') : 0.8998433583959902\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'concavity_mean', 'concave points_mean') : 0.9121240601503761\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'area_mean', 'compactness_mean') : 0.8910714285714286\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'area_mean', 'concavity_mean') : 0.8946115288220552\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'area_mean', 'concave points_mean') : 0.8928571428571429\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'compactness_mean', 'concavity_mean') : 0.8910714285714286\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'compactness_mean', 'concave points_mean') : 0.8910714285714286\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'concavity_mean', 'concave points_mean') : 0.8980889724310778\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('area_mean', 'compactness_mean', 'concavity_mean') : 0.8928571428571429\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('area_mean', 'compactness_mean', 'concave points_mean') : 0.8910401002506265\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('area_mean', 'concavity_mean', 'concave points_mean') : 0.8946115288220552\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('compactness_mean', 'concavity_mean', 'concave points_mean') : 0.9348997493734336\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean') : 0.8910714285714286\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'area_mean', 'concavity_mean') : 0.8928571428571429\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'area_mean', 'concave points_mean') : 0.8946115288220552\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'compactness_mean', 'concavity_mean') : 0.8963345864661655\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'compactness_mean', 'concave points_mean') : 0.8963659147869674\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'concavity_mean', 'concave points_mean') : 0.9051065162907269\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'area_mean', 'compactness_mean', 'concavity_mean') : 0.8928571428571429\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'area_mean', 'compactness_mean', 'concave points_mean') : 0.8910401002506265\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'area_mean', 'concavity_mean', 'concave points_mean') : 0.8946115288220552\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean') : 0.9138784461152882\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean') : 0.8963972431077695\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'area_mean', 'compactness_mean', 'concave points_mean') : 0.8911027568922305\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean') : 0.8928571428571429\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean') : 0.8963345864661655\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('area_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean') : 0.892825814536341\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean') : 0.8963972431077695\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concave points_mean') : 0.8911027568922305\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean') : 0.8946428571428571\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean') : 0.9033521303258146\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'area_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean') : 0.8910401002506265\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean') : 0.8893796992481203\nParams: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\nAccuracy with ('radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean') : 0.8893170426065163\nParams: {'voting': 'soft', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]} \n\n"
        }
      ],
      "metadata": {},
      "execution_count": 2
    },
    {
      "source": [
        "print(\"Best Accuracy:\", bestAccuracy)\n",
        "print(\"Feature Combination of Best Accuracy:\", bestCombination)\n",
        "print(\"Best Parameters of Best Accuracy:\", bestParams)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best Accuracy: 0.9348997493734336\nFeature Combination of Best Accuracy: ('compactness_mean', 'concavity_mean', 'concave points_mean')\nBest Parameters of Best Accuracy: {'voting': 'hard', 'weights': [92.3, 92.1, 92.6, 92.6, 93.3]}\n"
        }
      ],
      "metadata": {},
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkIud-ik8tY9"
      },
      "source": [
        "Poly Kernal Tests"
      ]
    },
    {
      "source": [
        "for nNumberOfFeatures in range(2, len(features)+1):\n",
        "    possibleCombinations = rSubset(features, nNumberOfFeatures) # Creates complete list of all combinations of\n",
        "    for combination in possibleCombinations:\n",
        "        currentDF = pd.DataFrame()\n",
        "        i = 0\n",
        "        for feature in combination:\n",
        "            currentDF.insert(i, feature, df[feature].to_list(), True)\n",
        "            i += 1\n",
        "\n",
        "        x = currentDF\n",
        "        y = dfLabels\n",
        "\n",
        "        model = SVC(kernel = 'poly')\n",
        "        # Set up the grid of parameters \n",
        "        hyperParams = {'degree': range(2, maxRange)\n",
        "                    'gamma': ['scale', 'auto']}\n",
        "        # Train the model in the grid search\n",
        "        kFolds = StratifiedKFold(n_splits = k, shuffle = True, random_state = 0)\n",
        "        search = GridSearchCV(model, hyperParams, cv = kFolds, scoring = 'accuracy')\n",
        "        search = search.fit(x, y)\n",
        "        # Show some of the results using a dataframe\n",
        "        dfResults = pd.DataFrame(search.cv_results_)\n",
        "        results = dfResults[['param_kernel', 'param_C', 'param_kernel', \\\n",
        "                    'mean_test_score', 'std_test_score']]\n",
        "        model = search.best_estimator_\n",
        "        # print(search.best_params_)\n",
        "\n",
        "        maxDepthRange = C_Range\n",
        "        trainScores, testScores = validation_curve(model, x, y, \\\n",
        "                    param_name = 'C', param_range = maxDepthRange, \\\n",
        "                    cv = kFolds, scoring = 'accuracy')\n",
        "        trainScoresMean = np.mean(trainScores, axis=1)\n",
        "        trainScoresStd = np.std(trainScores, axis=1)\n",
        "        testScoresMean = np.mean(testScores, axis=1)\n",
        "        testScoresStd = np.std(testScores, axis=1)\n",
        "\n",
        "        filteredTestScoresMean = [] # Include all test scores that are within STD of train scores mean\n",
        "        filteredTestScoresMeanIndex = [] \n",
        "        for param in ['C']:\n",
        "          maxDepthRange = C_Range\n",
        "          trainScores, testScores = validation_curve(model, x, y, \\\n",
        "                      param_name = param, param_range = maxDepthRange, \\\n",
        "                      cv = kFolds, scoring = 'accuracy')\n",
        "          trainScoresMean = np.mean(trainScores, axis=1)\n",
        "          trainScoresStd = np.std(trainScores, axis=1)\n",
        "          testScoresMean = np.mean(testScores, axis=1)\n",
        "          testScoresStd = np.std(testScores, axis=1)\n",
        "\n",
        "          filteredTestScoresMean = [] # Include all test scores that are within STD of train scores mean\n",
        "          filteredTestScoresMeanIndex = [] \n",
        "          for i in range(0, len(trainScoresMean)):\n",
        "              if testScoresMean[i] + testScoresStd[i] >= trainScoresMean[i]:\n",
        "                  filteredTestScoresMean.append(testScoresMean[i])\n",
        "                  filteredTestScoresMeanIndex.append(i)\n",
        "\n",
        "          print(\"Test Scores Left:\", len(filteredTestScoresMean))\n",
        "\n",
        "          bestScore = 0.0\n",
        "          bestScoreIndex = 0\n",
        "          for i in range(0, len(filteredTestScoresMean)):\n",
        "              if filteredTestScoresMean[i] > bestScore:\n",
        "                  bestScore = filteredTestScoresMean[i]\n",
        "                  bestScoreIndex = filteredTestScoresMeanIndex[i]\n",
        "\n",
        "          if len(filteredTestScoresMean) == 0:\n",
        "              bestScore = testScoresMean[search.best_params_[param] -1 ]\n",
        "              bestScoreIndex = search.best_params_[param] - 1\n",
        "          \n",
        "          highestAccuracy = (bestScore, bestScoreIndex) # Percent, depth \n",
        "\n",
        "          search.best_params_[param] = bestScoreIndex + 1\n",
        "\n",
        "          print(\"Accuracy with\", combination, \":\", highestAccuracy[0])\n",
        "          print(\"Params:\", search.best_params_, '\\n')\n",
        "\n",
        "        if highestAccuracy[0] > bestAccuracy:\n",
        "            bestAccuracy = highestAccuracy[0]\n",
        "            bestCombination = combination\n",
        "            bestDF = currentDF\n",
        "            bestParams = search.best_params_\n",
        "            bestModel = SVC(kernel=search.best_params_['kernel'], C=search.best_params_['C'], gamma=search.best_params_['gamma'])\n",
        "\n",
        "            confusion = np.zeros((2,2))\n",
        "            scores = cross_val_score(bestModel, x, y, cv = kFolds)\n",
        "            predicted = cross_val_predict(bestModel, x, y, cv = kFolds)\n",
        "            accuracy = scores.mean()\n",
        "            confusion = confusion_matrix(y, predicted)\n",
        "            confDF = pd.DataFrame(confusion)\n",
        "            confDF.columns = labels\n",
        "            confDF.index = labels\n",
        "\n",
        "            fig, ax = plt.subplots() # figsize=(6,10)\n",
        "            plt.title('Confusion matrix with best accuracy with SVM')\n",
        "            ax = sns.heatmap(confDF, annot = True, square=True, linewidth=3)\n",
        "            fig.savefig('Best Heatmap SVM.png')\n",
        "            plt.close()"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-4-eb3ea3c694ed>, line 16)",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-eb3ea3c694ed>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    'gamma': ['scale', 'auto']}\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "metadata": {},
      "execution_count": 4
    },
    {
      "source": [
        "x = bestDF\n",
        "y = dfLabels\n",
        "model = bestModel\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for param in ['n_neighbors', 'p']:\n",
        "  maxDepthRange = range(1, maxRange+1)\n",
        "  trainScores, testScores = validation_curve(model, x, y, \\\n",
        "              param_name = param, param_range = maxDepthRange, \\\n",
        "              cv = kFolds, scoring = 'accuracy')\n",
        "  trainScoresMean = np.mean(trainScores, axis=1)\n",
        "  trainScoresStd = np.std(trainScores, axis=1)\n",
        "  testScoresMean = np.mean(testScores, axis=1)\n",
        "  testScoresStd = np.std(testScores, axis=1)\n",
        "\n",
        "  if param == 'p':\n",
        "      colors = ['darkorange', 'navy']\n",
        "  else:\n",
        "      colors = ['red', 'green']\n",
        "\n",
        "  plt.plot(maxDepthRange, trainScoresMean, label = 'Training Score: ' + param, \\\n",
        "          color = colors[0], lw = 1, marker = 'o', markersize = 3)\n",
        "  plt.fill_between(maxDepthRange, trainScoresMean - trainScoresStd, \\\n",
        "                  trainScoresMean + trainScoresStd, alpha = 0.2, \\\n",
        "                  color = colors[0], lw = 1)\n",
        "  plt.plot(maxDepthRange, testScoresMean, label = 'Validation Score: ' + param, \\\n",
        "          color = colors[1], lw = 1, marker = 's', markersize = 3)\n",
        "  plt.fill_between(maxDepthRange, testScoresMean - testScoresStd, \\\n",
        "                  testScoresMean + testScoresStd, alpha = 0.2, \\\n",
        "                  color = colors[1], lw = 1)\n",
        "\n",
        "  '''\n",
        "  plt.title(\"Validation Curve with Best KNN Classifier using \" + param)\n",
        "  plt.xlabel(param + ' Parameter')\n",
        "  plt.ylabel(\"Score\")\n",
        "  plt.legend(loc=\"best\")\n",
        "\n",
        "  plt.show()\n",
        "  fig.savefig('KNN Validation Curve ' + param + '.png')\n",
        "  '''\n",
        "\n",
        "plt.title(\"Validation Curve with Best KNN Classifier\")\n",
        "plt.xlabel('Parameter')\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.show()\n",
        "fig.savefig('KNN Validation Curve.png')\n",
        "\n",
        "scores = cross_val_score(model, x, y, cv = kFolds)\n",
        "predicted = cross_val_predict(model, x, y, cv = kFolds)\n",
        "accuracy = scores.mean()\n",
        "confusion = confusion_matrix(y, predicted)\n",
        "confDF = pd.DataFrame(confusion)\n",
        "confDF.columns = labels\n",
        "confDF.index = labels\n",
        "\n",
        "fig, ax = plt.subplots() # figsize=(6,10)\n",
        "plt.title('Confusion Matrix with Best Accuracy (KNN)')\n",
        "ax = sns.heatmap(confDF, annot = True, square=True, linewidth=3)\n",
        "fig.savefig('Best Heatmap KNN.png')\n",
        "plt.close()\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    },
    {
      "source": [
        "#PCA Analysis\n",
        "pca = PCA(n_components = 2)\n",
        "print(\"bestDF:\", bestDF)\n",
        "x = bestDF.values\n",
        "print(x)\n",
        "pca.fit(x)\n",
        "print('Components using Scikit-learn =')\n",
        "print(pca.singular_values_)\n",
        "print(pca.components_)\n",
        "xP = pca.transform(x)\n",
        "currentDFPCA = pd.DataFrame(data = xP, columns = ['eig1', 'eig2'])\n",
        "\n",
        "#print(dfLabels)\n",
        "X = currentDFPCA\n",
        "Y = dfLabels # Labels\n",
        "\n",
        "# Plotting decision regions\n",
        "X = X.to_numpy()\n",
        "#print(\"X:\", X)\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 #Compute boundaries of painting space\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max-x_min)/1000),\n",
        "                    np.arange(y_min, y_max, (y_max-y_min)/1000)) #tesselation 0.1 - resolution\n",
        "\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "print(np.c_[xx.ravel(), yy.ravel()].shape)\n",
        "model.fit(bestDF,dfLabels)\n",
        "Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()])) # Predicting after inversing the PCA\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Defining the colors to use\n",
        "colors=['blue', 'red']\n",
        "markers = ['s', 'p']\n",
        "cmap = ListedColormap(colors)\n",
        "\n",
        "currentDFPCA['diagnosis'] = diagnosis\n",
        "\n",
        "# Plotting\n",
        "#print(currentDFPCA.head())\n",
        "ax = sns.scatterplot(data=currentDFPCA, x='eig1', y='eig2', hue = \"diagnosis\", palette=colors, style=\"diagnosis\", markers=markers)\n",
        "ax.contourf(xx, yy, Z, alpha=0.2, cmap=cmap) # Paint between boarders\n",
        "ax.set_title('Best KNN (based on Filtered Test Scores) Decision Regions plotted on PCA Space')\n",
        "plt.show()\n",
        "f.savefig(\"Decision Regions for KNN\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "metadata": {},
      "execution_count": 0
    }
  ]
}